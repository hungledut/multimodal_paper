{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFnWnDcI3qJJ",
        "outputId": "9da80395-a99a-4284-97e4-bbad8f85504f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OOE3u9uxylz",
        "outputId": "e4c0857f-36e5-4d73-c8e4-7c2cd61ccf0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available. Using GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    print(\"GPU is available. Using GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU is not available. Using CPU.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSO_G2wVfvmK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "\n",
        "path = \"/content/drive/MyDrive/Data_Image\"\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    # transforms.RandomHorizontalFlip(p=0.5),\n",
        "    # transforms.RandomRotation(degrees=15),\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "Image_dataset = datasets.ImageFolder(root=path, transform=transform)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsUqpFBGMv_b"
      },
      "outputs": [],
      "source": [
        "# Chia dữ liệu thành tập train và tập test\n",
        "train_dataset, test_dataset = random_split(Image_dataset, [0.7, 0.3])\n",
        "\n",
        "batch_size = 32\n",
        "# Tạo DataLoader để nạp dữ liệu theo batch\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ih9LgbcXcrBy",
        "outputId": "aba8a323-9d50-414d-d20e-bdd9bea1a569"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1346"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "len(Image_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6EGKDgNV-T0",
        "outputId": "711d106d-8bf4-40d7-cc34-fa1a813300c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "from torchvision.models import efficientnet_b0\n",
        "import torch.nn as nn\n",
        "\n",
        "class VisionModel(nn.Module):\n",
        "    def __init__(self, num_classes=16):\n",
        "        super(VisionModel, self).__init__()\n",
        "\n",
        "        self.efficientnet_b0 = efficientnet_b0(pretrained=False).to(device)\n",
        "\n",
        "        n_inputs = self.efficientnet_b0.classifier[1].in_features\n",
        "        self.efficientnet_b0.classifier[1] = nn.Sequential(\n",
        "            nn.Linear(n_inputs, num_classes, bias=True),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.efficientnet_b0(x)\n",
        "        return x\n",
        "\n",
        "num_classes = len(Image_dataset.classes)\n",
        "vision_model = VisionModel(num_classes).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjH2Qxf1FyGN",
        "outputId": "a3596fd8-8877-4022-b972-48694b2480f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VisionModel(\n",
            "  (efficientnet_b0): EfficientNet(\n",
            "    (features): Sequential(\n",
            "      (0): Conv2dNormActivation(\n",
            "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): SiLU(inplace=True)\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (2): Conv2dNormActivation(\n",
            "              (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
            "        )\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
            "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
            "        )\n",
            "        (1): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
            "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
            "        )\n",
            "      )\n",
            "      (3): Sequential(\n",
            "        (0): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
            "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
            "        )\n",
            "        (1): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
            "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
            "        )\n",
            "      )\n",
            "      (4): Sequential(\n",
            "        (0): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
            "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
            "        )\n",
            "        (1): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
            "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
            "        )\n",
            "        (2): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
            "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
            "        )\n",
            "      )\n",
            "      (5): Sequential(\n",
            "        (0): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
            "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
            "        )\n",
            "        (1): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
            "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
            "        )\n",
            "        (2): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
            "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
            "        )\n",
            "      )\n",
            "      (6): Sequential(\n",
            "        (0): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
            "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
            "        )\n",
            "        (1): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
            "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
            "        )\n",
            "        (2): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
            "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
            "        )\n",
            "        (3): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
            "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
            "        )\n",
            "      )\n",
            "      (7): Sequential(\n",
            "        (0): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
            "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
            "        )\n",
            "      )\n",
            "      (8): Conv2dNormActivation(\n",
            "        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): SiLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "    (classifier): Sequential(\n",
            "      (0): Dropout(p=0.2, inplace=True)\n",
            "      (1): Sequential(\n",
            "        (0): Linear(in_features=1280, out_features=16, bias=True)\n",
            "        (1): LogSoftmax(dim=1)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(vision_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWQtGz3wceDx"
      },
      "outputs": [],
      "source": [
        "def train_step(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               accuracy_fn):\n",
        "    train_loss, train_acc = 0, 0\n",
        "\n",
        "    for batch, (X, y) in enumerate(data_loader):\n",
        "        # Chuyển dữ liệu và mô hình lên GPU\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        model.to(device)\n",
        "\n",
        "        # 1. Forward pass\n",
        "        y_pred = model(X)\n",
        "\n",
        "        # 2. Calculate loss\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss.item()\n",
        "        train_acc += accuracy_fn(y_true=y,\n",
        "                                 y_pred=y_pred.argmax(dim=1)) # Go from logits -> pred labels\n",
        "\n",
        "        # 3. Optimizer zero grad\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 4. Loss backward\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. Optimizer step\n",
        "        optimizer.step()\n",
        "\n",
        "    # Calculate loss and accuracy per epoch and print out what's happening\n",
        "    train_loss /= len(data_loader)\n",
        "    train_acc /= len(data_loader)\n",
        "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n",
        "\n",
        "def test_step(data_loader: torch.utils.data.DataLoader,\n",
        "              model: torch.nn.Module,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              accuracy_fn):\n",
        "    test_loss, test_acc = 0, 0\n",
        "    model.eval() # put model in eval mode\n",
        "    # Turn on inference context manager\n",
        "    with torch.inference_mode():\n",
        "        for (X, y) in data_loader:\n",
        "            # Chuyển dữ liệu lên GPU\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            # 1. Forward pass\n",
        "            test_pred = model(X)\n",
        "\n",
        "            # 2. Calculate loss and accuracy\n",
        "            test_loss += loss_fn(test_pred, y).item()\n",
        "            test_acc += accuracy_fn(y_true=y,\n",
        "                y_pred=test_pred.argmax(dim=1) # Go from logits -> pred labels\n",
        "            )\n",
        "\n",
        "        # Adjust metrics and print out\n",
        "        test_loss /= len(data_loader)\n",
        "        test_acc /= len(data_loader)\n",
        "        print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bw3F8Rq1K0iG"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = optim.Adam(vision_model.parameters(), lr=0.0001)\n",
        "\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "    correct = torch.eq(y_true, y_pred).sum().item()  # torch.eq() calculates where two tensors are equal\n",
        "    acc = (correct / len(y_pred)) * 100\n",
        "    return acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uVOCDZ3Kv9R",
        "outputId": "6ee01da9-e685-47ca-dc6a-b05f0c751b10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "---------\n",
            "Train loss: 2.72064 | Train accuracy: 15.25%\n",
            "Test loss: 2.72022 | Test accuracy: 13.70%\n",
            "\n",
            "Epoch: 1\n",
            "---------\n",
            "Train loss: 2.57494 | Train accuracy: 16.62%\n",
            "Test loss: 2.68603 | Test accuracy: 14.03%\n",
            "\n",
            "Epoch: 2\n",
            "---------\n",
            "Train loss: 2.46577 | Train accuracy: 21.12%\n",
            "Test loss: 2.59280 | Test accuracy: 21.10%\n",
            "\n",
            "Epoch: 3\n",
            "---------\n",
            "Train loss: 2.36929 | Train accuracy: 25.60%\n",
            "Test loss: 2.84815 | Test accuracy: 25.73%\n",
            "\n",
            "Epoch: 4\n",
            "---------\n",
            "Train loss: 2.25036 | Train accuracy: 27.23%\n",
            "Test loss: 2.78632 | Test accuracy: 27.26%\n",
            "\n",
            "Epoch: 5\n",
            "---------\n",
            "Train loss: 2.10790 | Train accuracy: 33.01%\n",
            "Test loss: 2.81633 | Test accuracy: 30.07%\n",
            "\n",
            "Epoch: 6\n",
            "---------\n",
            "Train loss: 1.98455 | Train accuracy: 36.49%\n",
            "Test loss: 3.02947 | Test accuracy: 32.00%\n",
            "\n",
            "Epoch: 7\n",
            "---------\n",
            "Train loss: 1.83255 | Train accuracy: 39.62%\n",
            "Test loss: 2.65563 | Test accuracy: 30.71%\n",
            "\n",
            "Epoch: 8\n",
            "---------\n",
            "Train loss: 1.65752 | Train accuracy: 50.15%\n",
            "Test loss: 2.25705 | Test accuracy: 39.85%\n",
            "\n",
            "Epoch: 9\n",
            "---------\n",
            "Train loss: 1.47562 | Train accuracy: 53.58%\n",
            "Test loss: 3.04726 | Test accuracy: 31.59%\n",
            "\n",
            "Epoch: 10\n",
            "---------\n",
            "Train loss: 1.29155 | Train accuracy: 60.36%\n",
            "Test loss: 2.72073 | Test accuracy: 39.06%\n",
            "\n",
            "Epoch: 11\n",
            "---------\n",
            "Train loss: 1.19958 | Train accuracy: 61.79%\n",
            "Test loss: 2.88826 | Test accuracy: 45.00%\n",
            "\n",
            "Epoch: 12\n",
            "---------\n",
            "Train loss: 1.04166 | Train accuracy: 68.90%\n",
            "Test loss: 3.22484 | Test accuracy: 39.06%\n",
            "\n",
            "Epoch: 13\n",
            "---------\n",
            "Train loss: 0.92259 | Train accuracy: 72.55%\n",
            "Test loss: 2.96152 | Test accuracy: 44.90%\n",
            "\n",
            "Epoch: 14\n",
            "---------\n",
            "Train loss: 0.83973 | Train accuracy: 76.42%\n",
            "Test loss: 2.73247 | Test accuracy: 45.23%\n",
            "\n",
            "Epoch: 15\n",
            "---------\n",
            "Train loss: 0.72008 | Train accuracy: 78.31%\n",
            "Test loss: 2.43709 | Test accuracy: 44.83%\n",
            "\n",
            "Epoch: 16\n",
            "---------\n",
            "Train loss: 0.61003 | Train accuracy: 83.56%\n",
            "Test loss: 2.42392 | Test accuracy: 46.82%\n",
            "\n",
            "Epoch: 17\n",
            "---------\n",
            "Train loss: 0.62638 | Train accuracy: 83.04%\n",
            "Test loss: 2.87852 | Test accuracy: 49.89%\n",
            "\n",
            "Epoch: 18\n",
            "---------\n",
            "Train loss: 0.58297 | Train accuracy: 83.33%\n",
            "Test loss: 2.75971 | Test accuracy: 47.38%\n",
            "\n",
            "Epoch: 19\n",
            "---------\n",
            "Train loss: 0.50730 | Train accuracy: 85.60%\n",
            "Test loss: 3.32365 | Test accuracy: 47.62%\n",
            "\n",
            "Epoch: 20\n",
            "---------\n",
            "Train loss: 0.48331 | Train accuracy: 86.34%\n",
            "Test loss: 2.64518 | Test accuracy: 48.28%\n",
            "\n",
            "Epoch: 21\n",
            "---------\n",
            "Train loss: 0.43515 | Train accuracy: 89.06%\n",
            "Test loss: 2.27320 | Test accuracy: 51.09%\n",
            "\n",
            "Epoch: 22\n",
            "---------\n",
            "Train loss: 0.39109 | Train accuracy: 89.47%\n",
            "Test loss: 2.61794 | Test accuracy: 46.76%\n",
            "\n",
            "Epoch: 23\n",
            "---------\n",
            "Train loss: 0.41774 | Train accuracy: 88.72%\n",
            "Test loss: 2.81445 | Test accuracy: 49.00%\n",
            "\n",
            "Epoch: 24\n",
            "---------\n",
            "Train loss: 0.35391 | Train accuracy: 89.85%\n",
            "Test loss: 2.49712 | Test accuracy: 48.34%\n",
            "\n",
            "Epoch: 25\n",
            "---------\n",
            "Train loss: 0.39399 | Train accuracy: 88.89%\n",
            "Test loss: 2.41943 | Test accuracy: 49.41%\n",
            "\n",
            "Epoch: 26\n",
            "---------\n",
            "Train loss: 0.39552 | Train accuracy: 89.33%\n",
            "Test loss: 2.40472 | Test accuracy: 49.39%\n",
            "\n",
            "Epoch: 27\n",
            "---------\n",
            "Train loss: 0.34363 | Train accuracy: 90.27%\n",
            "Test loss: 2.31315 | Test accuracy: 50.61%\n",
            "\n",
            "Epoch: 28\n",
            "---------\n",
            "Train loss: 0.30644 | Train accuracy: 91.74%\n",
            "Test loss: 2.28719 | Test accuracy: 51.25%\n",
            "\n",
            "Epoch: 29\n",
            "---------\n",
            "Train loss: 0.31955 | Train accuracy: 91.22%\n",
            "Test loss: 2.27699 | Test accuracy: 48.68%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "epochs = 30\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch: {epoch}\\n---------\")\n",
        "    vision_model.train()\n",
        "\n",
        "    train_step(data_loader=train_loader,\n",
        "        model=vision_model,\n",
        "        loss_fn=loss_fn,\n",
        "        optimizer=optimizer,\n",
        "        accuracy_fn=accuracy_fn\n",
        "    )\n",
        "\n",
        "    vision_model.eval()\n",
        "    test_step(data_loader=test_loader,\n",
        "        model=vision_model,\n",
        "        loss_fn=loss_fn,\n",
        "        accuracy_fn=accuracy_fn\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}